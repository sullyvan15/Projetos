{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OnoBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdsZYg3_1RZ6"
      },
      "source": [
        "!pip install --upgrade \"ibm-watson>=4.7.1\"\n",
        "!pip install python-telegram-bot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1imWFtau8sLO"
      },
      "source": [
        "# Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbYtI7nL8r62"
      },
      "source": [
        "def updateEntidades(output, user_id):\n",
        "    for out in output['output']['entities']:\n",
        "        BANCO_DADOS[user_id]['ENTIDADES'].update({out['entity']: out['value']})\n",
        "    \n",
        "    if len(BANCO_DADOS[user_id]['ENTIDADES']) == 4:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuP2n_P39ZnG"
      },
      "source": [
        "def sugerirOculos(user_id):\n",
        "    catalogo = pd.read_csv('catalogo.csv', sep=';')\n",
        "    formato_oculos = {'oval': ['redondo', 'retangular', 'triangular'], 'quadrado': ['redondo', 'triangular'], 'redondo': ['quadrado', 'retangular', 'triangular']}[BANCO_DADOS[user_id]['ENTIDADES']['formato_do_rosto']]\n",
        "    cor = BANCO_DADOS[user_id]['ENTIDADES']['cor']\n",
        "    genero = BANCO_DADOS[user_id]['ENTIDADES']['genero']\n",
        "    \n",
        "    modelos = list()\n",
        "\n",
        "    for f in formato_oculos:\n",
        "        temp = catalogo.loc[(catalogo['formato_oculos'] == f) & (catalogo['genero'] == genero)]\n",
        "        modelos.append(temp)\n",
        "\n",
        "    opcao_sem_cor = pd.concat(modelos)\n",
        "    opcao_com_cor = opcao_sem_cor.loc[opcao_sem_cor['cor'] == cor]\n",
        "\n",
        "    if len(opcao_com_cor) == 0:\n",
        "        return 0, opcao_sem_cor\n",
        "    else:\n",
        "        return len(opcao_com_cor), opcao_com_cor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UtHKeu1ipS"
      },
      "source": [
        "# Watson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvPxinPs1lCA"
      },
      "source": [
        "ASSISTANT_APIKEY = '6SbPNEcnalIurb5LSlOnqr-DkdZBbWAZugC_JFkYFzUS'\n",
        "ASSISTANT_URL = 'https://api.us-south.assistant.watson.cloud.ibm.com/instances/7f639ca4-251a-4a66-b21f-b020a9c92ce3'\n",
        "ASSISTANT_ID = 'e0482367-a817-420e-b5a3-a27dd800aa0f'\n",
        "\n",
        "from ibm_watson import AssistantV2\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "\n",
        "authenticator = IAMAuthenticator(ASSISTANT_APIKEY)\n",
        "assistant = AssistantV2(\n",
        "    version='2020-04-01',\n",
        "    authenticator=authenticator\n",
        ")\n",
        "\n",
        "assistant.set_service_url(ASSISTANT_URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvgCZZw11roh"
      },
      "source": [
        "VISUAL_RECOGNITION_APIKEY = \"w3ZEWWwtmKkhjT8cCvmb7Tl7BA8XzEFS-2kYZEhaoG8u\"\n",
        "VISUAL_RECOGNITION_URL = 'https://api.us-south.visual-recognition.watson.cloud.ibm.com/instances/d247f614-69ad-410e-992f-c69df43501b0'\n",
        "CLASSIFIER_ID = 'DefaultCustomModel_962446588'\n",
        "\n",
        "from ibm_watson import VisualRecognitionV3\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "\n",
        "authenticator = IAMAuthenticator(VISUAL_RECOGNITION_APIKEY)\n",
        "visual_recognition = VisualRecognitionV3(\n",
        "    version='2018-03-19',\n",
        "    authenticator=authenticator\n",
        ")\n",
        "\n",
        "visual_recognition.set_service_url(VISUAL_RECOGNITION_URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX8E0T_M13xF"
      },
      "source": [
        "# Telegram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKQEq4gl172Y",
        "outputId": "9b21331e-34e4-44df-c175-2a5aebc72721"
      },
      "source": [
        "BANCO_DADOS = dict()\n",
        "\n",
        "APIKEY = '1462738723:AAHpUeLjo7Dgb2SOMG5ploK8-ngofpXmv9Q'\n",
        "\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
        "from telegram import ReplyKeyboardMarkup, ReplyKeyboardRemove, Update\n",
        "\n",
        "import logging, time\n",
        "\n",
        "updater = Updater(APIKEY, use_context=True)\n",
        "dp = updater.dispatcher\n",
        "\n",
        "dp.add_handler(MessageHandler(Filters.regex(r'mais'), ver_mais))\n",
        "dp.add_handler(MessageHandler(Filters.regex(r'outro'), ver_mais))\n",
        "\n",
        "dp.add_handler(MessageHandler(Filters.text, watson))\n",
        "dp.add_handler(MessageHandler(Filters.voice, classificadorSom)) \n",
        "dp.add_handler(MessageHandler(Filters.photo, classificadorImagem))\n",
        "\n",
        "updater.start_polling()\n",
        "updater.idle()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User id 1108603766 diz: Oi\n",
            "User id 1108603766 diz: Tchau\n",
            "User id 1108603766 diz: Quero o telefone da loja\n",
            "User id 1108603766 diz: Quero comprar uma lente\n",
            "User id 1108603766 diz: Não, obrigado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opQAUvwEB4-M"
      },
      "source": [
        "def ver_mais(bot, context):\n",
        "\n",
        "    user = bot.message.chat.id\n",
        "    print(\"User id {} diz: {}\".format(user, bot.message.text))\n",
        "    \n",
        "\n",
        "    ## Identifica usuario\n",
        "    chat_id = bot.message.chat.id\n",
        "\n",
        "    r = sugerirOculos(chat_id)\n",
        "\n",
        "    bot.message.reply_text('O que acha desse? Sua cara, né!')\n",
        "\n",
        "    escolhe_aleatorio = r[1].sample().iloc[0]['codigo']\n",
        "\n",
        "    bot.message.reply_photo('https://raw.githubusercontent.com/rhuam/datasets/master/oculos_ono/{}/img_({}).JPG'.format(escolhe_aleatorio, randint(1, 4)))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ajrJdOn2OJA"
      },
      "source": [
        "from random import randint\n",
        "\n",
        "def watson(bot, context):\n",
        "\n",
        "    user = bot.message.chat.id\n",
        "    print(\"User id {} diz: {}\".format(user, bot.message.text))\n",
        "\n",
        "    ## Identifica usuario\n",
        "    chat_id = bot.message.chat.id\n",
        "\n",
        "    if chat_id in BANCO_DADOS:\n",
        "        session_id = BANCO_DADOS[chat_id]['session_id']\n",
        "    else:\n",
        "        response = assistant.create_session(assistant_id=ASSISTANT_ID).get_result()\n",
        "        session_id = response['session_id']\n",
        "        BANCO_DADOS[chat_id] = {'session_id': session_id, 'ENTIDADES': {}}\n",
        "\n",
        "    ## Envia mensagem para Watson\n",
        "    response = assistant.message(\n",
        "        assistant_id=ASSISTANT_ID,\n",
        "        session_id=session_id,\n",
        "        input={\n",
        "        'message_type': 'text',\n",
        "        'text': bot.message.text\n",
        "        }\n",
        "    ).get_result()\n",
        "\n",
        "    for resposta in response['output']['generic']:\n",
        "        bot.message.reply_text(resposta['text'])\n",
        "\n",
        "    if 'Tchau' in resposta['text']:\n",
        "        assistant.delete_session(assistant_id=ASSISTANT_ID, session_id=session_id).get_result()\n",
        "        return None\n",
        "\n",
        "    if updateEntidades(response, chat_id):\n",
        "        r = sugerirOculos(chat_id)\n",
        "\n",
        "        if r[0] == 0:\n",
        "            bot.message.reply_text('Não encontrei um óculos da cor que vocês deseja, mas olha esse:')\n",
        "        else:\n",
        "            bot.message.reply_text('Encontrei {} óculo(s) para você.'.format(r[0]))\n",
        "    \n",
        "        escolhe_aleatorio = r[1].sample().iloc[0]['codigo']\n",
        "        URL = 'https://raw.githubusercontent.com/rhuam/datasets/master/oculos_ono/{}/img_({}).JPG'.format(escolhe_aleatorio, randint(1, 4))\n",
        "        print(URL)\n",
        "        bot.message.reply_photo(URL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VDabVaA4Pho"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "from joblib import load\n",
        "\n",
        "def classificadorSom(bot, context):\n",
        "    user = bot.message.chat.id\n",
        "    print(\"User id {} enviou um áudio\".format(user))\n",
        "\n",
        "    ## Identifica usuario\n",
        "    chat_id = bot.message.chat.id\n",
        "\n",
        "    if chat_id in BANCO_DADOS:\n",
        "        session_id = BANCO_DADOS[chat_id]['session_id']\n",
        "    else:\n",
        "        response = assistant.create_session(assistant_id=ASSISTANT_ID).get_result()\n",
        "        session_id = response['session_id']\n",
        "        BANCO_DADOS[chat_id] = {'session_id': session_id}\n",
        "\n",
        "    ## Salva o áudio\n",
        "    photo_file = bot.message.voice.get_file()\n",
        "    file_name = str(bot.message.voice.file_unique_id) + '.ogg'\n",
        "    photo_file.download(file_name)\n",
        "\n",
        "    ## Mensagem para aguardar\n",
        "    bot.message.reply_text(\"Só um momento, por favor!\")\n",
        "\n",
        "    ## Modelo de ML\n",
        "    modelo  = load('sound_recognition.joblib')\n",
        "\n",
        "\n",
        "    ## Predição\n",
        "    genero = modelo.predict(pd.DataFrame([file_name]))[0]\n",
        "\n",
        "    print(\"Voz do usuário {} é compatível com gênero {}\".format(user, genero))\n",
        "\n",
        "    mensagem = 'Eu sou ' + genero\n",
        "\n",
        "    ## Envia mensagem para Watson\n",
        "    response = assistant.message(\n",
        "        assistant_id=ASSISTANT_ID,\n",
        "        session_id=session_id,\n",
        "        input={\n",
        "        'message_type': 'text',\n",
        "        'text': mensagem\n",
        "        }\n",
        "    ).get_result()\n",
        "\n",
        "\n",
        "    for resposta in response['output']['generic']:\n",
        "        bot.message.reply_text(resposta['text'])\n",
        "\n",
        "    if updateEntidades(response, chat_id):\n",
        "        r = sugerirOculos(chat_id)\n",
        "\n",
        "        if r[0] == 0:\n",
        "            bot.message.reply_text('Não encontrei um óculos da cor que vocês deseja, mas olha esse:')\n",
        "        else:\n",
        "            bot.message.reply_text('Encontrei {} óculo(s) para você.'.format(r[0]))\n",
        "    \n",
        "        escolhe_aleatorio = r[1].sample().iloc[0]['codigo']\n",
        "        bot.message.reply_photo('https://raw.githubusercontent.com/rhuam/datasets/master/oculos_ono/{}/img_({}).JPG'.format(escolhe_aleatorio, randint(1, 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wLxtm7F6VuP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def classificadorImagem(bot, context):\n",
        "    user = bot.message.chat.id\n",
        "    print(\"User id {} enviou uma foto\".format(user))\n",
        "\n",
        "    ## Identifica usuario\n",
        "    chat_id = bot.message.chat.id\n",
        "\n",
        "    if chat_id in BANCO_DADOS:\n",
        "        session_id = BANCO_DADOS[chat_id]['session_id']\n",
        "    else:\n",
        "        response = assistant.create_session(assistant_id=ASSISTANT_ID).get_result()\n",
        "        session_id = response['session_id']\n",
        "        BANCO_DADOS[chat_id] = {'session_id': session_id}\n",
        "\n",
        "    ## Salva foto\n",
        "    photo_file = bot.message.photo[-1].get_file()\n",
        "    file_name = str(bot.message.photo[-1].file_unique_id) + '.jpg'\n",
        "    photo_file.download(file_name)\n",
        "\n",
        "    ## Mensagem para aguardar\n",
        "    bot.message.reply_text(\"Mais um momento, por favor!\")\n",
        "\n",
        "    ## Modelo de ML\n",
        "    with open(file_name, 'rb') as images_file:\n",
        "        classes = visual_recognition.classify(images_file=images_file, classifier_ids=[CLASSIFIER_ID]).get_result()\n",
        "\n",
        "    formato_rosto, score = '', 0\n",
        "    for c in classes['images'][0]['classifiers'][0]['classes']:\n",
        "        if c['score'] > score:\n",
        "            formato_rosto = c['class']\n",
        "\n",
        "\n",
        "    mensagem = \"Meu rosto é \" + {'Oval': 'oval', 'Square': 'quadrado', 'Round': 'redondo'}[formato_rosto]\n",
        "\n",
        "    print(\"Rosto do usuário {} é compatível com formato {}\".format(user, formato_rosto))\n",
        "\n",
        "\n",
        "    ## Envia mensagem para Watson\n",
        "    response = assistant.message(\n",
        "        assistant_id=ASSISTANT_ID,\n",
        "        session_id=session_id,\n",
        "        input={\n",
        "        'message_type': 'text',\n",
        "        'text': mensagem\n",
        "        }\n",
        "    ).get_result()\n",
        "\n",
        "\n",
        "    for resposta in response['output']['generic']:\n",
        "        bot.message.reply_text(resposta['text'])\n",
        "\n",
        "    if updateEntidades(response, chat_id):\n",
        "        r = sugerirOculos(chat_id)\n",
        "\n",
        "        if r[0] == 0:\n",
        "            bot.message.reply_text('Não encontrei um óculos da cor que vocês deseja, mas olha esse:')\n",
        "        else:\n",
        "            bot.message.reply_text('Encontrei {} óculo(s) para você.'.format(r[0]))\n",
        "    \n",
        "        escolhe_aleatorio = r[1].sample().iloc[0]['codigo']\n",
        "        bot.message.reply_photo('https://raw.githubusercontent.com/rhuam/datasets/master/oculos_ono/{}/img_({}).JPG'.format(escolhe_aleatorio, randint(1, 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4b6-_K5Wq8"
      },
      "source": [
        "# Classe do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S51bezNf5TtI"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class AudioDecode(BaseEstimator, TransformerMixin):\n",
        "    def __main__(self):\n",
        "        pass\n",
        "    \n",
        "    def __init__(self, offset=0.5, duration=1):\n",
        "        self.offset = offset\n",
        "        self.duration = duration\n",
        "\n",
        "    def fit(self, X, y = None):\n",
        "        self.X = X\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y = None):\n",
        "        X_ = list()\n",
        "        for index, value in X.iterrows():\n",
        "            audio_data, sr = librosa.load(value[0], offset=self.offset, duration=self.duration)\n",
        "            audio_stft = librosa.stft(audio_data)\n",
        "            audio_db = librosa.amplitude_to_db(abs(audio_stft))\n",
        "            X_.append(np.reshape(audio_db, audio_db.size))\n",
        "        \n",
        "        return pd.DataFrame(X_)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}